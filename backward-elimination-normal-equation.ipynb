{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "[Backward elimination](https://en.wikipedia.org/wiki/Stepwise_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import f\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('winequality-red.csv', sep=';')\n",
    "#data = pd.read_csv('winequality-white.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.iloc[:,:-1].to_numpy(), data.iloc[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples, num_features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(X)\n",
    "y = y.reshape((num_examples, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normal Equation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    '''\n",
    "    Returns the estimated parameters\n",
    "    as a (n+1,1) vector\n",
    "    [n: number of features].\n",
    "    '''\n",
    "    return np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(theta, X):\n",
    "    '''\n",
    "    Returns the hypothesis for the LinReg\n",
    "    theta: (n+1, 1) vector [n: # features]\n",
    "    X: (m, n+1) matrix [m: # examples]\n",
    "    '''\n",
    "    return X.dot(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Root Mean Squared Error](https://en.wikipedia.org/wiki/Root-mean-square_deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predicted, actual):\n",
    "    err = predicted - actual\n",
    "    return float(np.sqrt(err.T.dot(err)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F-test**:\n",
    "\n",
    "[F-test to compare regression models](https://en.wikipedia.org/wiki/F-test#Regression_problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_test(residuals_UR, residuals_R, params_UR, params_R, alpha):\n",
    "    '''\n",
    "    Performs an F-test between the unrestricted (UR)\n",
    "    and restricted (R) model, with the informed\n",
    "    level of significance (alpha).\n",
    "    Receives the residuals and number of paramaters\n",
    "    for each model.\n",
    "    Returns the F-statistic and F-critical,\n",
    "    respectively.\n",
    "    '''\n",
    "    sample_size = len(residuals_UR)\n",
    "    # Un-restricted RSS\n",
    "    rss_UR = residuals_UR.T.dot(residuals_UR)\n",
    "    # Restricted RSS\n",
    "    rss_R = residuals_R.T.dot(residuals_R)\n",
    "    \n",
    "    num = (rss_R-rss_UR)/(params_UR-params_R)\n",
    "    den = rss_UR/(sample_size-params_UR)\n",
    "    f_stat = num/den\n",
    "    f_crit = f.ppf(1.0-alpha,params_UR-params_R,sample_size-params_UR)\n",
    "    return f_stat, f_crit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X, y, alpha=0.05):\n",
    "    '''\n",
    "    BACKWARD ELIMINATION\n",
    "    Evaluates the models with one restriction\n",
    "    (one less feature), apart from the constant term\n",
    "    and compares with the unrestricted model,\n",
    "    using an F-test with the informed level\n",
    "    of significance (alpha).\n",
    "    Returns two lists whose sizes are the number\n",
    "    of features: the first one contains the results\n",
    "    for the F-tests (True: null hypothesis rejected);\n",
    "    teh second one, the RMSE if the corresponding feature\n",
    "    were dropped.\n",
    "    X must already account for the constant term\n",
    "    (i. e., it must already contain a one-valued first column).\n",
    "    '''\n",
    "    _, num_features = X.shape\n",
    "    unrestricted_theta = normal_equation(X,y)\n",
    "    H0_rejected, rmses = [True], [rmse(hypothesis(unrestricted_theta,X), y)]\n",
    "    \n",
    "    for restrict in range(1,num_features):\n",
    "        restricted_X = np.delete(X,restrict,axis=1)\n",
    "        restricted_theta = normal_equation(restricted_X,y)\n",
    "        \n",
    "        # Performing the F-test\n",
    "        unrestricted_residuals = hypothesis(unrestricted_theta,X) - y\n",
    "        restricted_residuals = hypothesis(restricted_theta,restricted_X) - y\n",
    "        f_stat, f_crit = f_test(unrestricted_residuals,restricted_residuals,\n",
    "                                num_features,num_features-1,alpha)\n",
    "        \n",
    "        # Evaluating the statistical significance\n",
    "        H0_rejected.append(bool(f_stat > f_crit))\n",
    "        rmses.append(rmse(hypothesis(restricted_theta,restricted_X),y))\n",
    "\n",
    "    return H0_rejected, rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0_rejected, rmses = feature_selection(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> REPORT:\n",
      "\n",
      "\n",
      "Feature number:  0\n",
      "Parameter might be zero?  False\n",
      "RMSE if dropped:  35.607128175661956\n",
      "\n",
      " --------------------------------------------------\n",
      "\n",
      "Feature number:  1\n",
      "Parameter might be zero?  True\n",
      "RMSE if dropped:  35.61252403044953\n",
      "\n",
      " --------------------------------------------------\n",
      "\n",
      "Feature number:  2\n",
      "Parameter might be zero?  True\n",
      "RMSE if dropped:  35.64830657984974\n",
      "\n",
      " --------------------------------------------------\n",
      "\n",
      "Feature number:  3\n",
      "Parameter might be zero?  True\n",
      "RMSE if dropped:  35.614877210046814\n",
      "\n",
      " --------------------------------------------------\n",
      "\n",
      "Feature number:  4\n",
      "Parameter might be zero?  False\n",
      "RMSE if dropped:  35.746411436249176\n",
      "\n",
      " --------------------------------------------------\n",
      "\n",
      "Feature number:  5\n",
      "Parameter might be zero?  False\n",
      "RMSE if dropped:  35.70781299296529\n",
      "\n",
      " --------------------------------------------------\n",
      "\n",
      "Feature number:  6\n",
      "Parameter might be zero?  True\n",
      "RMSE if dropped:  35.63184620931896\n",
      "\n",
      " --------------------------------------------------\n",
      "\n",
      "Feature number:  7\n",
      "Parameter might be zero?  True\n",
      "RMSE if dropped:  35.64486130535078\n",
      "\n",
      " --------------------------------------------------\n",
      "\n",
      "Feature number:  8\n",
      "Parameter might be zero?  False\n",
      "RMSE if dropped:  39.20816705737907\n",
      "\n",
      " --------------------------------------------------\n",
      "\n",
      "Feature number:  9\n",
      "Parameter might be zero?  False\n",
      "RMSE if dropped:  36.43733813418069\n",
      "\n",
      " --------------------------------------------------\n",
      "\n",
      "Feature number:  10\n",
      "Parameter might be zero?  False\n",
      "RMSE if dropped:  37.34273893807322\n",
      "\n",
      " --------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('> REPORT:\\n\\n')\n",
    "for i in range(num_features):\n",
    "    print('Feature number: ', i)\n",
    "    print('Parameter might be zero? ', not H0_rejected[i])\n",
    "    print('RMSE if dropped: ', rmses[i])\n",
    "    print('\\n', '-'*50 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features to eliminate:\n",
    "\n",
    "**White wine**: 6\n",
    "\n",
    "**Red wine**: 1, 3, 6, 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
